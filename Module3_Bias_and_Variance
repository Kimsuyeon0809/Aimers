Module3 ML개론- 서울대학교 김건희 교수님 강의 공부 내용 (2)

1. Generalization
- 학습 data로 일반화 -> unseen data에 적용
- ML 모델의 목적 : unseen data에서 잘 동작하는 것

2. Generalization Error (Unseen data에 대한 error)
- Underfitting : Generalization error < Traning eror
- Overfitting : Generalization error > Traning eror
- 1차 목표 : Overfitting, 2차 목표 : 과도한 Overfitting인 경우 traning error 손해 보며 test error 낮추기

3. Typical relation between capacity and error
- capacity와 training error는 반비례하지만, 학습의 목적은 generalization(일반화) error의 반비례
- validation set 사용해 학습 중 generalization error 예측
- training error는 바로 측정이 가능하지만 generalization error는 바로 측정이 불가해 최적의 capacity를 찾는 것에 어려움이 있음 

4. Regularization
- 정규화를 통해 과적합 해결 
- 목적함수 J(w) = (error) + λw^tw 
- 목적함수 J(w) 최소화 = Loss 최소화 & Capacity 최소
- λ : hyper parameter / training error가 아닌 일반화 error 낮추려는 목적
- 같은 차수의 모델에서도 λ의 크기가 크면 underfitting 될 가능성이 높고, λ가 0에 가까우면 overfitting 될 가능성이 높다.
- λw^tw : 과적합 방지하는 regularization 항

5. Bias & Variance
- Bias : 예측의 평균과 true값의 차이
- Variance : 데이터 평균과 각 데이터의 거리 제곱의 평균 (E[(x-u)^2])
- Test error = Bias + Variance
- Bias와 Variance는 trade-off 관계 -> 앙상블 사용

6. Overfitting vs Underfitting
6-1) 높은 variance는 overfitting을 암시
- 데이터가 없는 부분이 널뛰지 않도록, train data가 많을수록 variance 감소
- Variance와 모델의 복잡도는 비례
6-2) 높은 bias는 underfitting을 암시
- bias가 높다는 것은, 영점이 맞지 않다는 것과 같아서, 정확하지 않은 모델을 의미한다. 때문에 underfitting과 연관되고, 복잡도가 너무 낮아진다.
- bias를 줄이려면 모델의 복잡도를 높여야 한다. 하지만, 그러면 variance도 높아진다.(Bias와 Variance는 trade-off 관계이기 때문)

7. Recent Progress of LLM - GPT
- GPT : Generative Pretrained Transformer 
- 하나의 태스크에 집중하는 것이 아닌, 다용도 생성형 인공지능
- 사용자의 지시에 안전하며(차별적 발언X, 욕설X) 유용하게 대답
- GPT-3과 GPT-3.5의 차이 : RLHF(사람의 feedback으로부터 강화학습), Label로 지도학습 해 한 질문에 대해 여러 답변을 생성하도록 하고, 사람이 직접 답변에 대한 랭크를 세우는 원리
- GPT-4 : multimodal language model(text 뿐만 아니라 어떤 형식의 data도 이해), 사람이 보는 시험에서 뛰어난 성능 보임, Multilingual(한 모델이 다양한 언어 가능)
- GPT의 한계 : 없는 사실을 만들어냄, 질문에 따라 응답의 퀄리티가 달라짐, 많은 bias, 지식 업데이트가 자주 일어나지 않음, 경험을 통해 배우지 않음(개인정보 보호 측면), 답변을 검증하는 과정이 없음

